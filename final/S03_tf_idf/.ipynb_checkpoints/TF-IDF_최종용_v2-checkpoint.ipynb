{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF 구하기\n",
    "- 벡터화하기 전에 데이터 전처리\n",
    "   - document별 형태소 분석\n",
    "   - 미등록단어 처리\n",
    "   - 명사만 추출\n",
    "   - 불용어(stopwords) 처리\n",
    "- document별 단어로 tokenize되어 있는 것을 다시 합쳐서 각각 하나의 document로 만들기\n",
    "- 벡터화(vectorize) 하기\n",
    "- tf-idf 값 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CSV 데이터 불러오기\n",
    "clova_df = pd.read_csv(\"../../data/sentiment/sentiment_clova.csv\", index_col=0)\n",
    "kakao_df = pd.read_csv(\"../../data/sentiment/sentiment_mini.csv\", index_col=0)\n",
    "geni_df = pd.read_csv(\"../../data/sentiment/sentiment_gigagenie.csv\", index_col=0)\n",
    "nugu_df = pd.read_csv(\"../../data/sentiment/sentiment_nugu.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 데이터 합치기\n",
    "# 긍정 document\n",
    "pos_c_text = clova_df.positive_text[clova_df.positive_text.notnull()]\n",
    "pos_k_text = kakao_df.positive_text[kakao_df.positive_text.notnull()]\n",
    "pos_g_text = geni_df.positive_text[geni_df.positive_text.notnull()]\n",
    "pos_n_text = nugu_df.positive_text[nugu_df.positive_text.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 데이터 합치기\n",
    "# 부정 document\n",
    "neg_c_text = clova_df.negative_text[clova_df.negative_text.notnull()]\n",
    "neg_k_text = kakao_df.negative_text[kakao_df.negative_text.notnull()]\n",
    "neg_g_text = geni_df.negative_text[geni_df.negative_text.notnull()]\n",
    "neg_n_text = nugu_df.negative_text[nugu_df.negative_text.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clova_text = [pos_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(positive_text), len(negative_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'blog.naver.com/ppang7942/'로 시작하는 url 페이지의 데이터 거르기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <br>\n",
    "## 긍정 document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "### POS tagging하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.  Komoran 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('네코', 'NNP'), ('ㄴ', 'JX')]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "komoran.pos(\"네콘\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('척수', 'NNP'), ('장애인', 'NNP')]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "komoran.pos(\"척수 장애인\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('가스', 'NNP'), ('잠', 'NNG'), ('그', 'MM'), ('미', 'NNP')]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "komoran.pos(\"가스잠그미\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('삼행', 'NNG'), ('시', 'XSN')]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "komoran.pos(\"삼행시\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('교동', 'NNP'), ('제비집', 'NNG')]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "komoran.pos(\"교동제비집\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('교동', 'NNP'), ('스튜디오', 'NNP')]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "komoran.pos(\"교동스튜디오\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('올레', 'NNP'), ('tv', 'SL'), ('스카이', 'NNP'), ('라이프', 'NNP')]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "komoran.pos(\"올레tv스카이라이프\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from konlpy.tag import Komoran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "komoran = Komoran(userdic='./unregistered.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# 명사와 외래어만 뽑아내기위한 정규표현식\n",
    "p = re.compile('NN.*|SL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "results = []\n",
    "for i, brand_text in enumerate(positive_text):\n",
    "    pos_tagging_list = list(map(komoran.pos, brand_text))\n",
    "    print(\"pos tagging -\", i)\n",
    "    \n",
    "    docs = []\n",
    "    for doc in pos_tagging_list:\n",
    "        want_words = []\n",
    "        for word, pos in doc:\n",
    "            if p.match(pos):\n",
    "                want_words.append(word)\n",
    "        docs.append(want_words)\n",
    "    print(\"noun extract -\", i)\n",
    "    \n",
    "    results.append(sum(docs, []))\n",
    "    print(\"finish -\", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos tagging - 0\n",
      "noun extract - 0\n",
      "finish - 0\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for i, brand_text in enumerate(positive_text):\n",
    "    pos_tagging_list = list(map(komoran.pos, brand_text))\n",
    "    print(\"pos tagging -\", i)\n",
    "\n",
    "    docs = []\n",
    "    for doc in pos_tagging_list:\n",
    "        want_words = [word for word, pos in doc if p.match(pos)]         \n",
    "        docs.append(want_words)\n",
    "    print(\"noun extract -\", i)\n",
    "    \n",
    "    results.append(sum(docs, []))\n",
    "    print(\"finish -\", i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pickle로 일단 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(results, open('tfidf_pos_list2.pickle', \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "load_result = pickle.load(open('tfidf_pos_list2.pickle', \"rb\"))\n",
    "results = load_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "### stopword 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords = [line.strip() for line in open('./stopwordsKor.txt', encoding='utf-8')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "final_docs = []\n",
    "for doc in results:\n",
    "    unique_NN_words = set(doc)\n",
    "    final_NN_words = doc\n",
    "    \n",
    "    for word in unique_NN_words:\n",
    "        if word in stopwords:\n",
    "            while word in final_NN_words: final_NN_words.remove(word)\n",
    "    final_docs.append(final_NN_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from tqdm import tqdm_notebook\n",
    "stopword_dict = {}\n",
    "for s_word in stopwords:\n",
    "    stopword_dict[s_word] = 1\n",
    "\n",
    "final_docs = []\n",
    "for i, doc in enumerate(results):\n",
    "    unique_NN_words = set(doc)\n",
    "    final_NN_words = doc\n",
    "    \n",
    "    for word in tqdm_notebook(unique_NN_words):\n",
    "        if stopword_dict.get(word):\n",
    "            while True:\n",
    "                try:\n",
    "                    final_NN_words.remove(word)\n",
    "                except ValueError:\n",
    "                    break\n",
    "    print(\"finish -\", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "stopword_dict = {}\n",
    "for s_word in stopwords:\n",
    "    stopword_dict[s_word] = 1\n",
    "\n",
    "final_docs = []\n",
    "for i, doc in enumerate(results):\n",
    "    unique_NN_words = set(doc)\n",
    "    final_NN_words = doc\n",
    "    \n",
    "    for word in tqdm_notebook(unique_NN_words):\n",
    "        if stopword_dict.get(word):\n",
    "            final_NN_words = list(filter(lambda x: x!= word, final_NN_words))\n",
    "    final_docs.append(final_NN_words)\n",
    "    print(\"finish -\", i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "### document별 단어들을 각각의 document로 바꾸기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents = []\n",
    "for doc_words in final_docs:\n",
    "    document = \" \".join(doc_words)\n",
    "    documents.append(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents[0][:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "### 벡터화 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer     # 벡터 수 카운트 할 때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv=CountVectorizer(max_df=0.85, max_features=10000)     \n",
    "# 문서 집합에서 단어 토큰을 생성하고 각 단어의 수를 세어 BOW(Bag Of Words) 인코딩한 벡터를 만든다.\n",
    "# max_df=0.85란 말은 documents들에서 85%이상 나타나는 토큰(단어)를 무시하라는 것, \n",
    "# max_df=25란 말은 documents들에서 25번 이상 나타나는 토큰(단어)를 무시하라는 것,\n",
    "# maximum 단어의 개수를 1만개로 정함 - 빈도수가 높은 단어 순으로 1만개를 자름(메모리 에러 안나려고)\n",
    "# min_df=1, ngram_range=(1,1) 등은 default 값임  \n",
    "\n",
    "word_count_vector=cv.fit_transform(documents)      # vectorize된 word_count_vector\n",
    "feature_names=cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(cv.vocabulary_)      # 위에서 max_features를 10000으로 주었지만 단어 수가 그 이하였음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "### TF-IDF 적용\n",
    "- TF * IDF는 특정 문서 내에서 단어 빈도가 높을수록, 전체 문서들에는 그 단어를 포함한 문서가 적을수록 TF * IDF값이 높아지는 특징이 있다.\n",
    "- 이러한 특징을 이용해서 모든 문서에 나타나는 흔한 단어들을 걸러내며, 특정 단어가 가지는 중요도를 측정하는 데 사용된다.\n",
    "- 한마디로 TF * IDF 값은 특정 단어가 가지는 중요도!\n",
    "- TF(Term Frequency): 단어 빈도\n",
    "   - 해당 문서에서 단어가 나타나는 빈도수\n",
    "   - 문서의 길이가 길면 해당 단어의 실제 중요도와는 상관없이 단어의 빈도수는 증가될 확률이 높다.\n",
    "   - 위의 문제를 해결하기 위해 다음과 같이 표준화 -> (문서에서 단어가 나타나는 빈도수) / (모든 단어가 나타나는 빈도수)\n",
    "- IDF(Inverse Document Frequency): 역문헌 빈도\n",
    "   - 해당 단어의 일반적인 중요도를 나타내는 값\n",
    "   - log( 전체 문서의 수 / 해당 단어가 포함된 문서들의 수 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer    # Tf * idf 구할 때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)        # Tf-idf 가중치를 적용할 수 있도록 변환시켜줌\n",
    "tf_idf_matrix = tfidf_transformer.fit_transform(word_count_vector)\n",
    "\n",
    "feature_names=cv.get_feature_names()\n",
    "\n",
    "dense = tf_idf_matrix.todense()\n",
    "\n",
    "for i in range(len(dense)):\n",
    "    doc = dense[i].tolist()[0]           # dense[i].tolist()는 2차원 list, 예를들면 shape: (1,814)\n",
    "    phrase_scores = [pair for pair in zip(range(0, len(doc)), doc) if pair[1] > 0]      # 0의 값이 아닌것만 모아서 만듦\n",
    "\n",
    "    sorted_phrase_scores = sorted(phrase_scores, key=lambda t: t[1], reverse=True) # sorted(phrase_scores, key=lambda t: t[1] * -1)라고 해도 됨\n",
    "    for phrase, score in [(feature_names[word_id], score) for (word_id, score) in sorted_phrase_scores][:20]:\n",
    "        print('{0: <20} {1}'.format(phrase, score))      # 단어와 단어의 tf-idf 값을 출력\n",
    "    print()\n",
    "    ##### 이 부분은 테스트를 위해서 #####\n",
    "    if i == 3:     \n",
    "        break\n",
    "    ###############################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 추가 \n",
    "   - 클로바\n",
    "     1. 네콘\n",
    "     2. 척수장애인\n",
    "     3. 척수 장애인\n",
    "     4. 가스잠그미\n",
    "     5. 브라보라이프\n",
    "   - 카카오\n",
    "     1. 산타토익\n",
    "     2. 산타 토익\n",
    "     3. qm3 (뭔가 관련있는듯)\n",
    "     4. qm6 (뭔가 관련있는듯)\n",
    "     5. 삼행시\n",
    "   - 기가지니\n",
    "     1. 바바북\n",
    "     2. 바바펜\n",
    "     3. 바바키트\n",
    "     4. 교동 기가 아일랜드\n",
    "     5. 올레tv스카이라이프\n",
    "   - 누구\n",
    "     1. 아트리체 (아파트 관련) \\- '청계' 라는 단어와도 연관(청계 다우 아트리체)\n",
    "     2. qoo(qoo10 관련 사이트 때문에)\n",
    "     3. 범양건영 (아파트 관련)\n",
    "     \n",
    "- 삭제\n",
    "   - 클로바\n",
    "       1. li\n",
    "       2. txt\n",
    "       3. 유조\n",
    "       4. 엠게임\n",
    "       5. date\n",
    "   - 카카오\n",
    "       6. 조수용 (카카오 공동 대표)\n",
    "       7. 배틀필드 (관련성이 전혀 없는 것 같은데 자꾸 나옴)\n",
    "       8. 이석영 (카카오 AI 서비스 팀장)\n",
    "       9. rx (관련없어보임... 근데 많이 나오긴 함)\n",
    "       10. 콰르텟 (전혀 관련없는 \"카카오프렌즈 콰르텟 강남점에서 라이언에그번을 맛보다\" 이런거 많이 나옴)\n",
    "       \n",
    "- 렘런트유노마켓 blog.naver.com/ppang7942/ 블로그 데이터 삭제하고싶다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <br>\n",
    "## 부정 document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "### POS tagging하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.  Komoran 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('척수', 'NNP'), ('장애인', 'NNP')]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "komoran.pos(\"척수 장애인\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('척수', 'NNP'), ('장애인', 'NNP')]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "komoran.pos(\"척수장애인\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('무드', 'NNG'), ('등', 'NNB')]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "komoran.pos(\"무드등\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('반려', 'NNG'), ('견', 'NNG')]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "komoran.pos(\"반려견\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('샤오미', 'NNP')]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "komoran.pos(\"샤오미\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('척수', 'NNP'), ('장애인', 'NNP')]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "komoran.pos(\"척수 장애인\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('nugu', 'SL')]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "komoran.pos(\"nugu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('line out', 'NNG')]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "komoran.pos(\"line out\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('null', 'SL')]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "komoran.pos(\"null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('스포', 'NNP'), ('티', 'NNG'), ('지', 'NNB')]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "komoran.pos(\"스포티지\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('지니', 'NNP'), ('뮤직', 'NNP')]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "komoran.pos(\"지니뮤직\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('올레', 'NNP'), ('tv', 'SL'), ('스카이', 'NNP'), ('라이프', 'NNP')]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "komoran.pos(\"올레tv스카이라이프\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from konlpy.tag import Komoran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "komoran = Komoran(userdic='./unregistered.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# 명사와 외래어만 뽑아내기위한 정규표현식\n",
    "p = re.compile('NN.*|SL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "results = []\n",
    "for i, brand_text in enumerate(positive_text):\n",
    "    pos_tagging_list = list(map(komoran.pos, brand_text))\n",
    "    print(\"pos tagging -\", i)\n",
    "    \n",
    "    docs = []\n",
    "    for doc in pos_tagging_list:\n",
    "        want_words = []\n",
    "        for word, pos in doc:\n",
    "            if p.match(pos):\n",
    "                want_words.append(word)\n",
    "        docs.append(want_words)\n",
    "    print(\"noun extract -\", i)\n",
    "    \n",
    "    results.append(sum(docs, []))\n",
    "    print(\"finish -\", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos tagging - 0\n",
      "noun extract - 0\n",
      "finish - 0\n",
      "pos tagging - 1\n",
      "noun extract - 1\n",
      "finish - 1\n",
      "pos tagging - 2\n",
      "noun extract - 2\n",
      "finish - 2\n",
      "pos tagging - 3\n",
      "noun extract - 3\n",
      "finish - 3\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for i, brand_text in enumerate(negative_text):\n",
    "    pos_tagging_list = list(map(komoran.pos, brand_text))\n",
    "    print(\"pos tagging -\", i)\n",
    "\n",
    "    docs = []\n",
    "    for doc in pos_tagging_list:\n",
    "        want_words = [word for word, pos in doc if p.match(pos)]         \n",
    "        docs.append(want_words)\n",
    "    print(\"noun extract -\", i)\n",
    "    \n",
    "    results.append(sum(docs, []))\n",
    "    print(\"finish -\", i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pickle로 일단 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(results, open('tfidf_neg_list2.pickle', \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "load_result2 = pickle.load(open('tfidf_neg_list2.pickle', \"rb\"))\n",
    "results = load_result2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "### stopword 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords = [line.strip() for line in open('./stopwordsKor.txt', encoding='utf-8')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "final_docs = []\n",
    "for doc in results:\n",
    "    unique_NN_words = set(doc)\n",
    "    final_NN_words = doc\n",
    "    \n",
    "    for word in unique_NN_words:\n",
    "        if word in stopwords:\n",
    "            while word in final_NN_words: final_NN_words.remove(word)\n",
    "    final_docs.append(final_NN_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from tqdm import tqdm_notebook\n",
    "stopword_dict = {}\n",
    "for s_word in stopwords:\n",
    "    stopword_dict[s_word] = 1\n",
    "\n",
    "final_docs = []\n",
    "for i, doc in enumerate(results):\n",
    "    unique_NN_words = set(doc)\n",
    "    final_NN_words = doc\n",
    "    \n",
    "    for word in tqdm_notebook(unique_NN_words):\n",
    "        if stopword_dict.get(word):\n",
    "            while True:\n",
    "                try:\n",
    "                    final_NN_words.remove(word)\n",
    "                except ValueError:\n",
    "                    break\n",
    "    print(\"finish -\", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34d343d5a5f7481a85fa2440c8e58715"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4485b68300c4572b07d194b10b76d8f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "771840c0525d406a936a4aa0b5a30737"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de77130344a74edab496cf21f25ea585"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "stopword_dict = {}\n",
    "for s_word in stopwords:\n",
    "    stopword_dict[s_word] = 1\n",
    "\n",
    "final_docs = []\n",
    "for i, doc in enumerate(results):\n",
    "    unique_NN_words = set(doc)\n",
    "    final_NN_words = doc\n",
    "    \n",
    "    for word in tqdm_notebook(unique_NN_words):\n",
    "        if stopword_dict.get(word):\n",
    "            final_NN_words = list(filter(lambda x: x!= word, final_NN_words))\n",
    "    final_docs.append(final_NN_words)\n",
    "    #print(\"finish -\", i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "### document별 단어들을 각각의 document로 바꾸기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents = []\n",
    "for doc_words in final_docs:\n",
    "    document = \" \".join(doc_words)\n",
    "    documents.append(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'유선 래 연결 와이파이 연결 사용 음성 인식 스피커 일상 차지 역할 흐름 가운데 국내 업체 세계 시장 맥 지적 전문가 국내 업체 시장 확대 이유 길 지적 글 사기 기본 사례 네이버 카카오 날 하루 수준 카메라 인식 로그인 질문 마찬가지 대답 네이버 음악 듣기 결제 상태 지원 별도 이퀄라이저 설정 지하철역 자동차 추천 경로 검색 비교 효과 결과 근처 분식집 '"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0][:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "### 벡터화 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer     # 벡터 수 카운트 할 때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv=CountVectorizer(max_df=0.85, max_features=10000)     \n",
    "# 문서 집합에서 단어 토큰을 생성하고 각 단어의 수를 세어 BOW(Bag Of Words) 인코딩한 벡터를 만든다.\n",
    "# max_df=0.85란 말은 documents들에서 85%이상 나타나는 토큰(단어)를 무시하라는 것, \n",
    "# max_df=25란 말은 documents들에서 25번 이상 나타나는 토큰(단어)를 무시하라는 것,\n",
    "# maximum 단어의 개수를 1만개로 정함 - 빈도수가 높은 단어 순으로 1만개를 자름(메모리 에러 안나려고)\n",
    "# min_df=1, ngram_range=(1,1) 등은 default 값임  \n",
    "\n",
    "word_count_vector=cv.fit_transform(documents)      # vectorize된 word_count_vector\n",
    "feature_names=cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9954"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cv.vocabulary_)      # 위에서 max_features를 10000으로 주었지만 단어 수가 그 이하였음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'듣기': 2969,\n",
       " '이퀄라이저': 7067,\n",
       " '지하철역': 8068,\n",
       " '마인': 3315,\n",
       " '자비스': 7277,\n",
       " '중반': 7943,\n",
       " '실현': 5650,\n",
       " '생태계': 4824,\n",
       " '번성': 4068,\n",
       " '도태': 2824,\n",
       " '시범': 5473,\n",
       " '여원': 6162,\n",
       " '격화': 1447,\n",
       " '조짐': 7798,\n",
       " '진출': 8122,\n",
       " '세컨드': 5025,\n",
       " '메신저': 3483,\n",
       " '계좌': 1530,\n",
       " '개설': 1335,\n",
       " '이모티콘': 6968,\n",
       " '곳도': 1659,\n",
       " '린지': 3254,\n",
       " '전만': 7533,\n",
       " '경쟁자': 1496,\n",
       " '중립': 7940,\n",
       " '선상': 4909,\n",
       " '생물': 4806,\n",
       " 'ceo': 134,\n",
       " '주년': 7847,\n",
       " '소회': 5120,\n",
       " '시너지': 5449,\n",
       " '내부': 2324,\n",
       " '논의': 2421,\n",
       " '액션': 5927,\n",
       " '완결': 6476,\n",
       " '베스트': 4108,\n",
       " '브레인': 4435,\n",
       " '노동부': 2378,\n",
       " '권리': 1922,\n",
       " '다라': 2511,\n",
       " '베타서비스': 4118,\n",
       " '제지': 7749,\n",
       " '하루하루': 9406,\n",
       " '실무': 5624,\n",
       " '시각': 5430,\n",
       " '시행착오': 5524,\n",
       " '웹툰': 6713,\n",
       " '회화': 9883,\n",
       " '감안': 1259,\n",
       " '매니저': 3410,\n",
       " '역삼동': 6184,\n",
       " '데모': 2750,\n",
       " '세션': 5014,\n",
       " '테크니컬': 8897,\n",
       " '전산언어학': 7544,\n",
       " '자인': 7299,\n",
       " '최현정': 8430,\n",
       " '연구원': 6203,\n",
       " '킹스': 8791,\n",
       " '골든': 1643,\n",
       " '서클': 4878,\n",
       " '범죄도시': 4084,\n",
       " '제품군': 7751,\n",
       " '만회': 3367,\n",
       " '라인업': 3067,\n",
       " '악의': 5811,\n",
       " '점수': 7597,\n",
       " '필터링': 9379,\n",
       " '진미': 8104,\n",
       " '열흘': 6279,\n",
       " 'amp': 25,\n",
       " '상거래': 4728,\n",
       " '전환율': 7583,\n",
       " '격차': 1446,\n",
       " '아니야': 5715,\n",
       " '간단명료': 1216,\n",
       " '클라우드': 8762,\n",
       " '컴퓨팅': 8657,\n",
       " '축적': 8457,\n",
       " '건수': 1405,\n",
       " '정형': 7704,\n",
       " '센서': 5037,\n",
       " '시행': 5523,\n",
       " '소형': 5117,\n",
       " '연속': 6228,\n",
       " '성적': 4974,\n",
       " '구사': 1841,\n",
       " '은어': 6853,\n",
       " '비속어': 4487,\n",
       " '어린아이': 6019,\n",
       " '이해도': 7082,\n",
       " '차원': 8195,\n",
       " '실생활': 5630,\n",
       " '부인': 4317,\n",
       " '융통': 6847,\n",
       " '시간문제': 5433,\n",
       " '연극': 6206,\n",
       " '티켓': 9034,\n",
       " '쏜다': 5693,\n",
       " '견제': 1452,\n",
       " '니혼게이자이신문': 2494,\n",
       " '재팬': 7449,\n",
       " '신제품': 5598,\n",
       " '이례': 6958,\n",
       " '머니': 3448,\n",
       " 'exid': 266,\n",
       " '심술': 5660,\n",
       " 'yes': 1096,\n",
       " 'yeah': 1094,\n",
       " '수초': 5263,\n",
       " '간의': 1224,\n",
       " '맥락': 3436,\n",
       " '스노우': 5318,\n",
       " '캐럴': 8602,\n",
       " '카르': 8564,\n",
       " '토도': 8911,\n",
       " '전술': 7548,\n",
       " '스페인': 5389,\n",
       " '연합군': 6253,\n",
       " '속사정': 5125,\n",
       " '총살': 8410,\n",
       " '총검': 8405,\n",
       " '오은영': 6414,\n",
       " '박사': 3843,\n",
       " '육아': 6832,\n",
       " '한국인': 9475,\n",
       " '파급': 9046,\n",
       " '공산': 1680,\n",
       " '집계': 8141,\n",
       " '매도': 3411,\n",
       " '반박': 3877,\n",
       " '이해진': 7085,\n",
       " '의장': 6907,\n",
       " '살아남기': 4699,\n",
       " '자국': 7256,\n",
       " '국내외': 1876,\n",
       " '역차별': 6190,\n",
       " '다국적': 2501,\n",
       " '투명': 8968,\n",
       " '납부': 2305,\n",
       " '선발': 4904,\n",
       " '주자': 7885,\n",
       " '꼬리표': 2197,\n",
       " '회피': 9882,\n",
       " '국정': 1898,\n",
       " '액수': 5928,\n",
       " '커튼': 8639,\n",
       " '가습기': 1163,\n",
       " '통신업': 8946,\n",
       " '돌입': 2854,\n",
       " '태반': 8856,\n",
       " '자급': 7258,\n",
       " '유통망': 6812,\n",
       " '붕괴': 4423,\n",
       " '통신비': 8944,\n",
       " '아이콘': 5774,\n",
       " '최다': 8417,\n",
       " '거래소': 1370,\n",
       " 'kmspico': 484,\n",
       " '악성': 5805,\n",
       " '승모': 5419,\n",
       " '외숙모': 6510,\n",
       " '공항': 1712,\n",
       " '공황': 1716,\n",
       " '네티즌': 2366,\n",
       " '사이에서': 4632,\n",
       " '맞춤법': 3403,\n",
       " '파괴': 9044,\n",
       " '동아': 2897,\n",
       " '이상우': 6989,\n",
       " '단독': 2561,\n",
       " '슈와': 5309,\n",
       " '재테크': 7446,\n",
       " '총집결': 8413,\n",
       " '화도': 9801,\n",
       " '걸음': 1416,\n",
       " 'ma': 540,\n",
       " '연간': 6193,\n",
       " '명도': 3521,\n",
       " '지장': 8048,\n",
       " '통신비밀보호법': 8945,\n",
       " '바이오': 3833,\n",
       " '가이드라인': 1182,\n",
       " '근거': 1986,\n",
       " '식별': 5531,\n",
       " '개시': 1341,\n",
       " '구매욕': 1836,\n",
       " '현행법': 9704,\n",
       " '축제': 8458,\n",
       " '현장': 9698,\n",
       " '잠자리': 7348,\n",
       " '호칭': 9761,\n",
       " '정우성': 7668,\n",
       " '초가': 8370,\n",
       " '멸종': 3515,\n",
       " '벙어리': 4100,\n",
       " '웹브라우저': 6712,\n",
       " 'ip': 428,\n",
       " '방문자': 3956,\n",
       " '트럼프': 8991,\n",
       " '경기장': 1474,\n",
       " '환승': 9841,\n",
       " '셔틀버스': 5052,\n",
       " '종목': 7818,\n",
       " '선수': 4914,\n",
       " '올림픽': 6453,\n",
       " '하이라이트': 9431,\n",
       " '백과사전': 4023,\n",
       " '평창': 9183,\n",
       " '동계': 2865,\n",
       " '서울까지': 4861,\n",
       " '필립스': 9372,\n",
       " '라이팅': 3066,\n",
       " '사랑합니다': 4576,\n",
       " '중국어': 7931,\n",
       " '학습량': 9452,\n",
       " '지난번': 8003,\n",
       " '지진': 8055,\n",
       " '새벽': 4780,\n",
       " '당사자': 2620,\n",
       " '토론': 8913,\n",
       " '불평': 4415,\n",
       " '개인화': 1346,\n",
       " '순항': 5293,\n",
       " '선거구': 4890,\n",
       " '늑장': 2474,\n",
       " '오명': 6383,\n",
       " '지방': 8018,\n",
       " '광역': 1785,\n",
       " '기초': 2106,\n",
       " '정수': 7657,\n",
       " '조정': 7794,\n",
       " '공직': 1703,\n",
       " '선거법': 4891,\n",
       " '개정안': 1348,\n",
       " '문턱': 3688,\n",
       " '출마자': 8470,\n",
       " '차질': 8200,\n",
       " '여야': 6159,\n",
       " '현영': 9695,\n",
       " '분유': 4373,\n",
       " '겨냥': 1440,\n",
       " '가루': 1138,\n",
       " '기저귀': 2097,\n",
       " '이곳저곳': 6923,\n",
       " '증가세': 7976,\n",
       " '발굴': 3902,\n",
       " '실적': 5639,\n",
       " '둔화': 2943,\n",
       " '산타토익': 4686,\n",
       " '태부족': 8857,\n",
       " '웃어봐': 6640,\n",
       " '투표수': 8979,\n",
       " '한겨레': 9465,\n",
       " '광범위': 1780,\n",
       " '소화': 5119,\n",
       " '약관': 5963,\n",
       " '픽사': 9362,\n",
       " '베이': 4112,\n",
       " '파문': 9060,\n",
       " '파기': 9047,\n",
       " '시민': 5467,\n",
       " '검은사막': 1421,\n",
       " '점령': 7595,\n",
       " '후발': 9903,\n",
       " '핸디캡': 9620,\n",
       " '관측': 1770,\n",
       " '한글판': 9484,\n",
       " '맞대응': 3396,\n",
       " '태세': 8860,\n",
       " '임박': 7206,\n",
       " '고군분투': 1538,\n",
       " '뮤지컬': 3717,\n",
       " '배우': 4010,\n",
       " '노랫말': 2384,\n",
       " '넘버': 2353,\n",
       " 'impossible': 413,\n",
       " 'dream': 217,\n",
       " '통계청': 8935,\n",
       " 'kosis': 487,\n",
       " '비염': 4493,\n",
       " '레이스': 3115,\n",
       " '미용실': 3756,\n",
       " '항구': 9570,\n",
       " '수수료': 5224,\n",
       " '폭우': 9239,\n",
       " '동원': 2901,\n",
       " '참치': 8225,\n",
       " '생도': 4798,\n",
       " '상회': 4775,\n",
       " '소속': 5087,\n",
       " '황치열': 9863,\n",
       " '컴백': 8654,\n",
       " 'bb': 70,\n",
       " '동사': 2888,\n",
       " '컨센서스': 8645,\n",
       " '매수': 3417,\n",
       " '직전': 8087,\n",
       " '한차례': 9528,\n",
       " '하향': 9441,\n",
       " '상향': 4771,\n",
       " '전고': 7511,\n",
       " '길드': 2127,\n",
       " '대장': 2695,\n",
       " '줌인터넷': 7918,\n",
       " '인턴십': 7148,\n",
       " 'zum': 1107,\n",
       " '기획자': 2118,\n",
       " '인턴': 7147,\n",
       " '사원': 4626,\n",
       " '모집': 3582,\n",
       " '피처': 9353,\n",
       " '국립전파연구원': 1880,\n",
       " '물음표': 3709,\n",
       " '세뇌': 5002,\n",
       " '동물': 2882,\n",
       " '채팅': 8261,\n",
       " '분출': 4377,\n",
       " '참여자': 8223,\n",
       " '명가': 3517,\n",
       " '우승': 6592,\n",
       " '롯데닷컴': 3172,\n",
       " '한국말': 9472,\n",
       " 'mt': 592,\n",
       " '돌파구': 2858,\n",
       " '마켓': 3325,\n",
       " '컬리': 8650,\n",
       " '출범': 8472,\n",
       " '유통업': 6813,\n",
       " '영역': 6301,\n",
       " '전환기': 7582,\n",
       " '킬러': 8788,\n",
       " '황성진': 9861,\n",
       " '기관': 2043,\n",
       " '한국소비자원': 9473,\n",
       " '몰입': 3606,\n",
       " '동명': 2880,\n",
       " '이인': 7035,\n",
       " '지칭': 8059,\n",
       " '브이': 4447,\n",
       " '라이브': 3062,\n",
       " 'live': 523,\n",
       " '출연': 8477,\n",
       " '방탄소년단': 3982,\n",
       " '지민': 8017,\n",
       " '건의': 1407,\n",
       " '유입': 6800,\n",
       " 'nlp': 628,\n",
       " '의욕': 6903,\n",
       " '대중교통': 2700,\n",
       " '비전': 4503,\n",
       " '유명': 6770,\n",
       " '텀블러': 8881,\n",
       " '인형': 7151,\n",
       " '갖가지': 1312,\n",
       " '군부대': 1907,\n",
       " '시설': 5481,\n",
       " '화제': 9822,\n",
       " '남짓': 2300,\n",
       " 'ktx': 495,\n",
       " '단적': 2576,\n",
       " 'g메일': 350,\n",
       " '이해력': 7083,\n",
       " '만족도': 3361,\n",
       " '가스': 1159,\n",
       " '벨브': 4126,\n",
       " '유기': 6750,\n",
       " '미러링': 3736,\n",
       " '코웨이': 8690,\n",
       " '시선': 5480,\n",
       " '불신': 4406,\n",
       " 'drs': 219,\n",
       " '고무': 1569,\n",
       " '진화': 8127,\n",
       " '표출': 9264,\n",
       " '주유소': 7881,\n",
       " '오랫동안': 6369,\n",
       " '탐색': 8844,\n",
       " '재즈': 7441,\n",
       " '텔레그램': 8901,\n",
       " 'gm': 329,\n",
       " '수입': 5250,\n",
       " '접근성': 7609,\n",
       " '강자': 1304,\n",
       " 'xxx': 1091,\n",
       " '지명': 8015,\n",
       " '목표액': 3600,\n",
       " '연내': 6211,\n",
       " '장면': 7375,\n",
       " '홍채': 9798,\n",
       " '도용': 2810,\n",
       " '제값': 7708,\n",
       " '집토끼': 8154,\n",
       " '유다': 6756,\n",
       " '불가피': 4385,\n",
       " '문맥': 3672,\n",
       " '도출': 2821,\n",
       " '취급': 8503,\n",
       " '저자': 7479,\n",
       " '평판': 9185,\n",
       " '랭킹': 3086,\n",
       " 'crank': 165,\n",
       " '패턴': 9133,\n",
       " '내일': 2334,\n",
       " '골자': 1649,\n",
       " '신설': 5578,\n",
       " 'view': 985,\n",
       " '개편': 1354,\n",
       " '실비': 5627,\n",
       " '보험': 4221,\n",
       " '청구': 8321,\n",
       " '서치': 4877,\n",
       " '김상범': 2141,\n",
       " '리더': 3198,\n",
       " '전개': 7507,\n",
       " '게재': 1439,\n",
       " '행위': 9631,\n",
       " 'my': 602,\n",
       " '길고양이': 2125,\n",
       " '여성': 6154,\n",
       " '가전제품': 1187,\n",
       " '독자': 2835,\n",
       " '엘지': 6127,\n",
       " '속편': 5132,\n",
       " '보일러': 4206,\n",
       " '봉사': 4278,\n",
       " '명예': 3534,\n",
       " '포진': 9218,\n",
       " '경상북도': 1486,\n",
       " '울릉군': 6631,\n",
       " '미현': 3769,\n",
       " '지리': 8013,\n",
       " '승자': 5424,\n",
       " '김연지': 2147,\n",
       " '경계': 1471,\n",
       " 'hey': 372,\n",
       " 'hot': 386,\n",
       " '사재기': 4640,\n",
       " '수상': 5218,\n",
       " 'lg유플러스': 514,\n",
       " '장애인': 7397,\n",
       " '감수': 1255,\n",
       " '이봉': 6975,\n",
       " '우연이': 6596,\n",
       " '선착순': 4923,\n",
       " '수조': 5254,\n",
       " '밤새': 3940,\n",
       " '일례': 7161,\n",
       " '쇼핑카트': 5181,\n",
       " '일라이': 7159,\n",
       " '장애물': 7395,\n",
       " '히스토리': 9946,\n",
       " '준수': 7911,\n",
       " '원본': 6670,\n",
       " '클로': 8770,\n",
       " '유영민': 6790,\n",
       " '과기': 1720,\n",
       " '정통부': 7700,\n",
       " '장관': 7358,\n",
       " '이어': 7015,\n",
       " '방통': 3983,\n",
       " '엇박자': 6080,\n",
       " '청와대': 8335,\n",
       " '자원': 7293,\n",
       " '국산': 1891,\n",
       " '유념': 6752,\n",
       " '김민서': 2136,\n",
       " '촉감': 8401,\n",
       " '비의': 4498,\n",
       " '범인': 4082,\n",
       " '소매': 5078,\n",
       " '감자': 1264,\n",
       " '생원': 4817,\n",
       " '이야기책': 7012,\n",
       " '연예인': 6236,\n",
       " '도서': 2800,\n",
       " 'isbn': 440,\n",
       " '특가': 9002,\n",
       " '서서': 4852,\n",
       " '시청자': 5508,\n",
       " 'sk브로드밴드': 815,\n",
       " 'iptv': 435,\n",
       " '근접': 2000,\n",
       " '외출복': 6517,\n",
       " '비결': 4464,\n",
       " '한국정보화진흥원': 9479,\n",
       " 'nia': 626,\n",
       " '논문': 2418,\n",
       " 'eu': 260,\n",
       " '유럽연합': 6762,\n",
       " '민간': 3774,\n",
       " 'rd': 750,\n",
       " '투자가': 8974,\n",
       " '뒷받침': 2950,\n",
       " '인당': 7104,\n",
       " '소득': 5073,\n",
       " '체감': 8347,\n",
       " '양극': 5978,\n",
       " '지목': 8016,\n",
       " '고지': 1614,\n",
       " '프랑스': 9296,\n",
       " '이탈리아': 7069,\n",
       " '워치': 6647,\n",
       " '전화통': 7581,\n",
       " '상대방': 4736,\n",
       " '마블': 3288,\n",
       " '본질': 4267,\n",
       " '피쳐': 9354,\n",
       " '통신업체': 8947,\n",
       " '하현': 9442,\n",
       " '확신': 9834,\n",
       " '내재': 2335,\n",
       " '의존': 6909,\n",
       " '가능성': 1126,\n",
       " '배분': 3998,\n",
       " '낙동강': 2265,\n",
       " '오리아': 6378,\n",
       " '신세': 5579,\n",
       " '오염': 6411,\n",
       " '에어': 6096,\n",
       " 'airvisual': 16,\n",
       " '측정': 8513,\n",
       " '대도시': 2645,\n",
       " '도시': 2803,\n",
       " '구독자': 1825,\n",
       " '형성': 9728,\n",
       " '구별': 1839,\n",
       " '범죄': 4083,\n",
       " '억양': 6050,\n",
       " '원천': 6685,\n",
       " '화상': 9810,\n",
       " '립싱크': 3256,\n",
       " '비음': 4497,\n",
       " '이데일리': 6943,\n",
       " '미애': 3752,\n",
       " '일자': 7184,\n",
       " '출혈': 8491,\n",
       " '거품': 1394,\n",
       " '비상근무': 4483,\n",
       " '최선': 8422,\n",
       " '불감증': 4386,\n",
       " '수위': 5246,\n",
       " '관세': 1759,\n",
       " '위안': 6728,\n",
       " '절하': 7592,\n",
       " '만지': 3362,\n",
       " '환율': 9843,\n",
       " '사설': 4602,\n",
       " '미중': 3760,\n",
       " '무역': 3648,\n",
       " '마찰': 3320,\n",
       " '설주': 4944,\n",
       " '대란': 2649,\n",
       " '뒷수습': 2953,\n",
       " '인민': 7114,\n",
       " '정책': 7694,\n",
       " '이해관계자': 7081,\n",
       " '동네북': 2875,\n",
       " '주의보': 7882,\n",
       " '십상': 5668,\n",
       " '납치': 2309,\n",
       " '감금': 1241,\n",
       " '성폭행': 4983,\n",
       " '과시': 1729,\n",
       " '딜레마': 3005,\n",
       " '대북': 2670,\n",
       " '식량': 5529,\n",
       " '에도': 6083,\n",
       " '비핵화': 4520,\n",
       " '교착': 1809,\n",
       " '고수': 1586,\n",
       " '물가': 3696,\n",
       " '협상': 9713,\n",
       " '우선순위': 6588,\n",
       " '증산': 7983,\n",
       " '타진': 8823,\n",
       " '자산': 7278,\n",
       " '비상': 4482,\n",
       " '포트폴리오': 9230,\n",
       " '집단': 8145,\n",
       " '베팅': 4121,\n",
       " '소송': 5088,\n",
       " '여기저기': 6136,\n",
       " '곡소리': 1633,\n",
       " '뭉칫돈': 3715,\n",
       " '가세': 1156,\n",
       " '버블': 4060,\n",
       " '로펌': 3164,\n",
       " '법무법인': 4089,\n",
       " '대륙': 2654,\n",
       " '도약': 2807,\n",
       " '가업': 1171,\n",
       " '승계': 5416,\n",
       " '오지': 6421,\n",
       " '축복': 8453,\n",
       " '결집': 1463,\n",
       " '병행': 4166,\n",
       " '회담': 9867,\n",
       " '황교안': 9855,\n",
       " '김성식': 2145,\n",
       " '오신환': 6407,\n",
       " '승부': 5420,\n",
       " '손학규': 5153,\n",
       " '민주당': 3784,\n",
       " '중대': 7935,\n",
       " '지대': 8006,\n",
       " '신당': 5555,\n",
       " '최저임금': 8428,\n",
       " '재계': 7419,\n",
       " 'oecd': 654,\n",
       " '노동': 2376,\n",
       " '위월': 6731,\n",
       " '수출': 5265,\n",
       " '마이너스': 3310,\n",
       " '반도체': 3869,\n",
       " '어부': 6029,\n",
       " '동산': 2889,\n",
       " '한파': 9534,\n",
       " '가계': 1114,\n",
       " '법정': 4095,\n",
       " '아시아나항공': 5761,\n",
       " '입찰': 7244,\n",
       " '공고': 1662,\n",
       " '종규': 7816,\n",
       " '용병': 6562,\n",
       " '빅데이터': 4522,\n",
       " '삼성카드': 4716,\n",
       " '육박': 6828,\n",
       " 'ms': 589,\n",
       " '의기투합': 6887,\n",
       " '정호': 7705,\n",
       " '승부수': 5421,\n",
       " '한진': 9525,\n",
       " '공정위': 1697,\n",
       " '차기': 8179,\n",
       " '총수': 8411,\n",
       " '조원태': 7789,\n",
       " '미달': 3730,\n",
       " '현대': 9680,\n",
       " '상여금': 4750,\n",
       " '대우조선해양': 2688,\n",
       " '노사': 2395,\n",
       " '단협': 2585,\n",
       " '교섭': 1803,\n",
       " '기아': 2078,\n",
       " '사내': 4568,\n",
       " '스타트': 5354,\n",
       " '메디톡스': 3474,\n",
       " '대웅제약': 2689,\n",
       " '보톡스': 4216,\n",
       " 'lgu': 513,\n",
       " '광선': 1781,\n",
       " '홈쇼핑': 9787,\n",
       " '옛말': 6351,\n",
       " '삼성물산': 4715,\n",
       " '부문': 4298,\n",
       " '약자': 5970,\n",
       " '본업': 4260,\n",
       " '롯데쇼핑': 3174,\n",
       " '창사': 8236,\n",
       " '풀무': 9274,\n",
       " '주사': 7863,\n",
       " '지배': 8019,\n",
       " '확립': 9832,\n",
       " '가려움': 1135,\n",
       " '보습제': 4195,\n",
       " '달래': 2593,\n",
       " '고혈압': 1630,\n",
       " '체크': 8366,\n",
       " '요시': 6539,\n",
       " '시크': 5512,\n",
       " '초간': 8371,\n",
       " '스트레칭': 5374,\n",
       " '쇼크': 5177,\n",
       " '화학': 9827,\n",
       " '울상': 6635,\n",
       " '회복': 9869,\n",
       " '젤메': 7759,\n",
       " '디톡스': 3000,\n",
       " '분쟁': 4376,\n",
       " '먹구름': 3457,\n",
       " '증권업': 7979,\n",
       " '대어': 2681,\n",
       " '표류': 9252,\n",
       " '분식회계': 4370,\n",
       " '심사': 5659,\n",
       " '감리': 1251,\n",
       " '임상': 7208,\n",
       " '골다공증': 1639,\n",
       " '치료제': 8518,\n",
       " '특허': 9014,\n",
       " '호재': 9758,\n",
       " '이식': 7008,\n",
       " '유상증자': 6780,\n",
       " '전봉준': 7541,\n",
       " '결의': 1461,\n",
       " '김원봉': 2151,\n",
       " '신념': 5554,\n",
       " '주검': 7842,\n",
       " '진실': 8109,\n",
       " '노란빛': 2380,\n",
       " '복수': 4235,\n",
       " '스포츠': 5395,\n",
       " '동갑내기': 2862,\n",
       " '웃음꽃': 6641,\n",
       " '승점': 5426,\n",
       " '프리미어리그': 9313,\n",
       " '시티': 5517,\n",
       " '돈방석': 2843,\n",
       " '피플': 9360,\n",
       " '양형': 6005,\n",
       " '사법': 4593,\n",
       " '건설': 1402,\n",
       " '통한': 8958,\n",
       " '한미글로벌': 9499,\n",
       " '총괄': 8406,\n",
       " '부회장': 4348,\n",
       " '농협': 2438,\n",
       " '상호금융': 4773,\n",
       " '한국투자공사': 9481,\n",
       " 'mou': 584,\n",
       " '인공위성': 7098,\n",
       " 'kaist': 465,\n",
       " '학술': 9451,\n",
       " '마라톤': 3274,\n",
       " '영웅': 6302,\n",
       " '서윤복': 4868,\n",
       " '국립서울현충원': 1879,\n",
       " '안장': 5846,\n",
       " '콩쿠르': 8717,\n",
       " '투어': 8972,\n",
       " '오피니언': 6433,\n",
       " '칼럼': 8597,\n",
       " '사상누각': 4598,\n",
       " '확대경': 9831,\n",
       " '수첩': 5262,\n",
       " '넷마블': 2370,\n",
       " '신작': 5595,\n",
       " '여의도': 6163,\n",
       " '기지개': 2103,\n",
       " '청량리역': 8326,\n",
       " '롯데캐슬': 3177,\n",
       " 'skyl': 811,\n",
       " '양가': 5976,\n",
       " '희소성': 9941,\n",
       " '집값': 8139,\n",
       " '대구': 2632,\n",
       " '지하철': 8066,\n",
       " '죽전역': 7907,\n",
       " '도보': 2797,\n",
       " '주상': 7866,\n",
       " '복합': 4246,\n",
       " 'mba': 553,\n",
       " '입성': 7229,\n",
       " '비즈니스': 4507,\n",
       " '스토리텔링': 5367,\n",
       " '총망라': 8409,\n",
       " '양성': 5987,\n",
       " '무궁무진': 3620,\n",
       " '특화': 9016,\n",
       " '강의': 1303,\n",
       " '공영': 1689,\n",
       " '타협안': 8827,\n",
       " '파업전야': 9069,\n",
       " '타결': 8795,\n",
       " '뇌물': 2441,\n",
       " '김학의': 2170,\n",
       " '구속영장': 1850,\n",
       " '백성': 4034,\n",
       " '눈높이': 2453,\n",
       " '세종대왕': 5022,\n",
       " '동상': 2890,\n",
       " '수렴': 5204,\n",
       " '이름값': 6961,\n",
       " '서울대': 4862,\n",
       " '자녀': 7262,\n",
       " '부실': 4309,\n",
       " '학회': 9461,\n",
       " '참석': 8221,\n",
       " '김종석': 2160,\n",
       " '기상청': 2072,\n",
       " '구모': 1837,\n",
       " '매출액': 3425,\n",
       " '형제': 9730,\n",
       " '아담': 5716,\n",
       " 'wave': 1057,\n",
       " '입수': 7231,\n",
       " '걸림돌': 1415,\n",
       " 'qa': 737,\n",
       " 'olleh': 665,\n",
       " 'giga': 325,\n",
       " '무선랜': 3639,\n",
       " '통장': 8953,\n",
       " '하나에': 9390,\n",
       " '공인인증서': 1694,\n",
       " '하나로': 9389,\n",
       " '젊은이들': 7593,\n",
       " '은행가': 6858,\n",
       " '체크카드': 8368,\n",
       " '아버지': 5747,\n",
       " '입출금': 7247,\n",
       " '출타': 8485,\n",
       " '텔레비': 8902,\n",
       " '고스톱': 1587,\n",
       " '대세': 2677,\n",
       " '대안': 2679,\n",
       " '사드': 4572,\n",
       " '모양새': 3572,\n",
       " '일체': 7190,\n",
       " '슬픔': 5414,\n",
       " '각자': 1208,\n",
       " '중첩': 7965,\n",
       " '활약': 9851,\n",
       " '동맹': 2878,\n",
       " '간첩': 1227,\n",
       " '터미네이터': 8875,\n",
       " '파격': 9041,\n",
       " '트라우마': 8984,\n",
       " '천대': 8280,\n",
       " '완파': 6487,\n",
       " '결재': 1462,\n",
       " 'どうした': 1111,\n",
       " '시타': 5514,\n",
       " '무스': 3642,\n",
       " 'nhn': 624,\n",
       " 'next': 622,\n",
       " 'human': 392,\n",
       " 'network': 618,\n",
       " '복잡계': 4240,\n",
       " 'complex': 156,\n",
       " '지고': 7995,\n",
       " '세계관': 4992,\n",
       " '헤지펀드': 9675,\n",
       " '주연': 7875,\n",
       " '담보': 2608,\n",
       " '공정': 1695,\n",
       " '약점': 5971,\n",
       " '금융인': 2018,\n",
       " '부자': 4319,\n",
       " '중범죄': 7944,\n",
       " '가난': 1124,\n",
       " '경범죄': 1479,\n",
       " '재생산': 7436,\n",
       " '경찰': 1502,\n",
       " '정당화': 7629,\n",
       " '창조': 8242,\n",
       " '독점': 2836,\n",
       " '통제': 8954,\n",
       " '브라더': 4430,\n",
       " '홍수': 9792,\n",
       " '함정': 9551,\n",
       " '유의': 6795,\n",
       " '편향': 9174,\n",
       " '천사': 8286,\n",
       " '악마': 5803,\n",
       " '청력': 8327,\n",
       " '체계': 8350,\n",
       " '노하우': 2408,\n",
       " '장악': 7393,\n",
       " '어른': 6018,\n",
       " '나기': 2225,\n",
       " '원유': 6678,\n",
       " '생산량': 4811,\n",
       " 'bd': 74,\n",
       " '사우디아라비아': 4624,\n",
       " '수출량': 5266,\n",
       " 'opec': 668,\n",
       " '사무총장': 4589,\n",
       " '균형': 1948,\n",
       " '강변': 1291,\n",
       " '전성시대': 7546,\n",
       " '기술적': 2077,\n",
       " '윤리': 6838,\n",
       " 'clova': 147,\n",
       " '소모': 5081,\n",
       " '손잡이': 5148,\n",
       " '장시간': 7386,\n",
       " '배려': 3996,\n",
       " '앙탈': 5892,\n",
       " '의인': 6905,\n",
       " '커플': 8640,\n",
       " '발매': 3910,\n",
       " '되풀이': 2923,\n",
       " '중학교': 7967,\n",
       " '프로그래밍': 9301,\n",
       " '군더더기': 1906,\n",
       " '공산품': 1681,\n",
       " '창출': 8243,\n",
       " '취향저격': 8511,\n",
       " '긴장': 2121,\n",
       " '탕진': 8850,\n",
       " 'speaker': 843,\n",
       " '몰두': 3604,\n",
       " '엘리': 6124,\n",
       " '이별': 6974,\n",
       " '템포': 8904,\n",
       " '외계인': 6502,\n",
       " '지식인': 8030,\n",
       " '필살기': 9373,\n",
       " '가방': 1149,\n",
       " '모음': 3575,\n",
       " '칫솔': 8556,\n",
       " '살균': 4691,\n",
       " '시발': 5471,\n",
       " '리가': 3192,\n",
       " '맥북': 3437,\n",
       " '패드': 9123,\n",
       " '언니네': 6053,\n",
       " '아시': 5758,\n",
       " '이웃': 7026,\n",
       " '세입': 5020,\n",
       " '윤종신': 6842,\n",
       " '신기하': 5551,\n",
       " 'ml': 575,\n",
       " '에펠탑': 6113,\n",
       " '신나': 5553,\n",
       " '설거지': 4930,\n",
       " '집안일': 8149,\n",
       " '옛날': 6350,\n",
       " '페퍼톤스': 9158,\n",
       " 'ready': 754,\n",
       " 'type': 929,\n",
       " '참견': 8218,\n",
       " '문물': 3675,\n",
       " 'ux': 951,\n",
       " '해답': 9580,\n",
       " '풀리': 9273,\n",
       " '간다': 1214,\n",
       " '캘린더': 8618,\n",
       " '불시': 4405,\n",
       " '요정': 6544,\n",
       " '도의': 2814,\n",
       " '아이러니': 5765,\n",
       " '선생님': 4911,\n",
       " '티맵': 9022,\n",
       " '겨울왕국': 1442,\n",
       " '외출': 6516,\n",
       " '뉴에이지': 2465,\n",
       " '귀뚜라미': 1932,\n",
       " '얼굴': 6063,\n",
       " '증정': 7989,\n",
       " '통일': 8952,\n",
       " '다나': 2504,\n",
       " '라나': 3038,\n",
       " '무트': 3661,\n",
       " '면포': 3512,\n",
       " '메모': 3478,\n",
       " '부축': 4334,\n",
       " '우측': 6607,\n",
       " '기로': 2058,\n",
       " '첨단': 8310,\n",
       " '부가세': 4282,\n",
       " '홀라당': 9780,\n",
       " '제시카': 7728,\n",
       " '구가': 1820,\n",
       " '기능인': 2051,\n",
       " '보아': 4197,\n",
       " '기온': 2087,\n",
       " '이정재': 7044,\n",
       " '송혜교': 5174,\n",
       " '블랙아웃': 4453,\n",
       " '사무실': 4588,\n",
       " '편견': 9162,\n",
       " '절단': 7585,\n",
       " '와인': 6470,\n",
       " '포장지': 9214,\n",
       " '저가': 7459,\n",
       " '임의': 7212,\n",
       " '이탈': 7068,\n",
       " '높이': 2439,\n",
       " '한밤': 9500,\n",
       " '야간': 5938,\n",
       " '리셋': 3223,\n",
       " '아미': 5744,\n",
       " '유혹': 6821,\n",
       " 'wake': 1052,\n",
       " 'up': 943,\n",
       " 'word': 1074,\n",
       " '만듦새': 3348,\n",
       " '애니': 5909,\n",
       " '후면': 9902,\n",
       " '한대': 9490,\n",
       " '거란': 1368,\n",
       " '시멘트': 5465,\n",
       " '변기': 4134,\n",
       " '시공': 5437,\n",
       " '별짓': 4161,\n",
       " '월세': 6698,\n",
       " '철물': 8297,\n",
       " '원주': 6683,\n",
       " '다이소': 2537,\n",
       " '라텍스': 3071,\n",
       " '종이컵': 7824,\n",
       " '덩어리': 2743,\n",
       " '수세미': 5222,\n",
       " '건조': 1409,\n",
       " '여드름': 6141,\n",
       " '일회': 7197,\n",
       " '바늘': 3812,\n",
       " '알콜': 5872,\n",
       " ...}"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "### TF-IDF 적용\n",
    "- TF * IDF는 특정 문서 내에서 단어 빈도가 높을수록, 전체 문서들에는 그 단어를 포함한 문서가 적을수록 TF * IDF값이 높아지는 특징이 있다.\n",
    "- 이러한 특징을 이용해서 모든 문서에 나타나는 흔한 단어들을 걸러내며, 특정 단어가 가지는 중요도를 측정하는 데 사용된다.\n",
    "- 한마디로 TF * IDF 값은 특정 단어가 가지는 중요도!\n",
    "- TF(Term Frequency): 단어 빈도\n",
    "   - 해당 문서에서 단어가 나타나는 빈도수\n",
    "   - 문서의 길이가 길면 해당 단어의 실제 중요도와는 상관없이 단어의 빈도수는 증가될 확률이 높다.\n",
    "   - 위의 문제를 해결하기 위해 다음과 같이 표준화 -> (문서에서 단어가 나타나는 빈도수) / (모든 단어가 나타나는 빈도수)\n",
    "- IDF(Inverse Document Frequency): 역문헌 빈도\n",
    "   - 해당 단어의 일반적인 중요도를 나타내는 값\n",
    "   - log( 전체 문서의 수 / 해당 단어가 포함된 문서들의 수 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer    # Tf * idf 구할 때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out                  0.2343521109627114\n",
      "미니언즈                 0.12819475081624657\n",
      "펌웨어                  0.12819475081624657\n",
      "wave                 0.12034297589977073\n",
      "nonnull              0.11247143563490924\n",
      "엘지                   0.09230022058769753\n",
      "반려견                  0.08837041371314297\n",
      "약관                   0.08717243055504767\n",
      "보호자                  0.08233993087879049\n",
      "float                0.07230306576529881\n",
      "목적어                  0.07230306576529881\n",
      "와서                   0.07178906045709808\n",
      "후에                   0.07178906045709808\n",
      "셀리                   0.06967224920513042\n",
      "필립스                  0.06666127042444822\n",
      "for                  0.06426939179137671\n",
      "int                  0.06426939179137671\n",
      "parse                0.06426939179137671\n",
      "선풍기                  0.06333840836830039\n",
      "잠시                   0.06333840836830039\n",
      "\n",
      "취약점                  0.12963442266623498\n",
      "보험료                  0.12454112383263523\n",
      "선생님                  0.10082677318484944\n",
      "크림                   0.09785374015421339\n",
      "수영                   0.09362486081450304\n",
      "핫스팟                  0.09362486081450304\n",
      "라섹                   0.07922103607381027\n",
      "새벽                   0.07922103607381027\n",
      "민정                   0.07898231191723404\n",
      "치약                   0.07898231191723404\n",
      "보험                   0.07201912370346387\n",
      "입맛                   0.07201912370346387\n",
      "펌웨어                  0.07201912370346387\n",
      "포터블                  0.07116635647579156\n",
      "kakao                0.06769912450048632\n",
      "기내식                  0.06769912450048632\n",
      "채영                   0.06769912450048632\n",
      "파워볼                  0.06769912450048632\n",
      "내일                   0.06481721133311749\n",
      "마무리                  0.06481721133311749\n",
      "\n",
      "영성                   0.18893367979721692\n",
      "예제                   0.1861968540851737\n",
      "종교                   0.1303377978596216\n",
      "파이썬                  0.12989190486058663\n",
      "lte                  0.1205939204454733\n",
      "취약점                  0.11305680041763123\n",
      "명상                   0.11171811245110423\n",
      "스포티지                 0.11171811245110423\n",
      "예수                   0.11171811245110423\n",
      "청소                   0.09044544033410498\n",
      "하만카돈                 0.09044544033410498\n",
      "특허                   0.08378858433832817\n",
      "iptv                 0.07537120027842081\n",
      "보험                   0.07537120027842081\n",
      "외출                   0.07537120027842081\n",
      "가격표                  0.07085012992395635\n",
      "벽걸이                  0.06783408025057873\n",
      "옛날                   0.06783408025057873\n",
      "올레                   0.06783408025057873\n",
      "장면                   0.06783408025057873\n",
      "\n",
      "아리야                  0.25560483364127234\n",
      "아리아                  0.24988273733953745\n",
      "아리                   0.1444634575244201\n",
      "신지                   0.13457454830604818\n",
      "연면적                  0.13021378317574253\n",
      "티맵                   0.12539105046552984\n",
      "김종민                  0.12234049846004381\n",
      "코요테                  0.12234049846004381\n",
      "무드등                  0.12103695089883845\n",
      "뮤직메이트                0.12056831775531715\n",
      "쿠폰                   0.09761044427325681\n",
      "예린                   0.09175537384503285\n",
      "유효                   0.08980160873139627\n",
      "블루원                  0.08563834892203066\n",
      "flo                  0.07952132399902848\n",
      "거래량                  0.07716372336340298\n",
      "오버                   0.07716372336340298\n",
      "인재                   0.07716372336340298\n",
      "nu                   0.07340429907602629\n",
      "tid                  0.07340429907602629\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)        # Tf-idf 가중치를 적용할 수 있도록 변환시켜줌\n",
    "tf_idf_matrix = tfidf_transformer.fit_transform(word_count_vector)\n",
    "\n",
    "feature_names=cv.get_feature_names()\n",
    "\n",
    "dense = tf_idf_matrix.todense()\n",
    "\n",
    "for i in range(len(dense)):\n",
    "    doc = dense[i].tolist()[0]           # dense[i].tolist()는 2차원 list, 예를들면 shape: (1,814)\n",
    "    phrase_scores = [pair for pair in zip(range(0, len(doc)), doc) if pair[1] > 0]      # 0의 값이 아닌것만 모아서 만듦\n",
    "\n",
    "    sorted_phrase_scores = sorted(phrase_scores, key=lambda t: t[1], reverse=True) # sorted(phrase_scores, key=lambda t: t[1] * -1)라고 해도 됨\n",
    "    for phrase, score in [(feature_names[word_id], score) for (word_id, score) in sorted_phrase_scores][:20]:\n",
    "        print('{0: <20} {1}'.format(phrase, score))      # 단어와 단어의 tf-idf 값을 출력\n",
    "    print()\n",
    "    ##### 이 부분은 테스트를 위해서 #####\n",
    "    if i == 3:     \n",
    "        break\n",
    "    ###############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
